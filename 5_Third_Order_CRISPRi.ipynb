{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Higher-Order Expression-Growth Rate Relationships\n",
    "\n",
    "The following code uses the pairwise continuous epistasis model to predict bacterial growth rate following three CRISPRi perturbations. It also quantifies growth rates from cells with these three-sgRNA constructs using a similar growth rate calculation as employed in previous code. The predictions from the continuous epistasis model outperform a coupling-insensitve Null model across all orders of CRISPRi perturbations.\n",
    "\n",
    "6/28/22 - Ryan Otto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "import regex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import math\n",
    "import itertools\n",
    "import plot_defaults\n",
    "plot_defaults.change_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '220815'\n",
    "input_path = 'input_files'\n",
    "output_path = 'intermediate_files'\n",
    "figure_path = 'Figures'\n",
    "file_path = 'intermediate_files'\n",
    "read_file_list = ['T0_S1', 'T2_S2', 'T4_S3', 'T6_S4', 'T8_S5', 'T10_S6']  # File prefix names\n",
    "BC_list = ['TGAAAG', 'CCATGC', 'CATGAT', 'ACTAGG', 'TAGACT', 'TCATAC']  # Relevant barcodes\n",
    "# \"Targets\" are the desired sgRNA constructs at each CRISPRi location\n",
    "sg1targets = ['gdhA_1_42_C', 'negC_rand_42', 'dapA_3_214_C', 'dapA_3_214_B_MM9', 'gdhA_1_42_B_MM8']\n",
    "sg2targets = ['dapB_1_18_B_MM11', 'negC_rand_42', 'gltB_3_284_B_MM10', 'dapB_1_18_C', 'gltB_3_284_C']\n",
    "sg3targets = ['folA_1_56_B_MM10', 'negC_rand_42', 'thyA_3_233_C', 'folA_1_56_B_MM3', 'thyA_3_233_B_MM5',\n",
    "             'purN_3_238_B_MM11', 'purL_3_201_C', 'purL_3_201_B_MM5', 'purN_1_86_C']\n",
    "sgRNA2seq = {}  # Deconvolutes sgRNA ID and sequence\n",
    "with open(f'{input_path}/Tri_FASTA.txt') as f:\n",
    "    full_seq = f.readlines()\n",
    "    for i, line in enumerate(full_seq):\n",
    "        if line[0] == '>':\n",
    "            sgRNA2seq[line[1:-1]] = str(Seq(full_seq[i+2][35:55]).reverse_complement())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{file_path}/220815_pair_avals.pickle', 'rb') as handle:\n",
    "    pair_avals = pickle.load(handle)\n",
    "with open(f'{file_path}/220815_repression_mean.pickle', 'rb') as handle:\n",
    "    qPCR_vals = pickle.load(handle)\n",
    "with open(f'{file_path}/220815_hill_elements.pickle', 'rb') as handle:\n",
    "    hill_elements = pickle.load(handle)\n",
    "with open(f'{file_path}/220815_pairwise_gr_min.pickle', 'rb') as handle:\n",
    "    min_gr = pickle.load(handle)  # Minimum growth rate observed in the pairwise experiment\n",
    "with open(f'{input_path}/turbidostat_GR.pickle', 'rb') as handle:\n",
    "    turb_gr = pickle.load(handle)\n",
    "with open(f'{file_path}/220815_df_growth_pool_filt_rescale.pickle', 'rb') as handle:\n",
    "    pairwise_gr_rescale = pickle.load(handle)\n",
    "with open(f'{file_path}/220815_df_growth_pool_filt_sem_rescale.pickle', 'rb') as handle:\n",
    "    pairwise_sem_rescale = pickle.load(handle)\n",
    "# This file was saved from this analysis. It can be regenerated by uncommenting code below, replacing the old file\n",
    "with open(f'{input_path}/third_order_counts.pickle', 'rb') as handle:\n",
    "    total_sgRNA_BC = pickle.load(handle)  # sgRNA IDs from sequencing position 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seqs(file_name, seq_path):\n",
    "    \"\"\"Extract sequences from paired-end FASTQ files\n",
    "    Arguments:\n",
    "    file_name: Prefix for file to extract sequences from\n",
    "    seq_path: Path to sequencing files\n",
    "    Returns:\n",
    "    sequences: A dictionary containing lists of Read 1 and Read 2 sequences\n",
    "    \"\"\"\n",
    "    sequences = {}\n",
    "    for read in ['R1', 'R2']:\n",
    "        sequences[read] = []\n",
    "        with open(f'{seq_path}/{file_name}_L001_{read}_001.fastq', \"r\") as handle:\n",
    "            lines = handle.read().splitlines()\n",
    "            for temp_seq in lines[1::4]:  # Extract all sequences\n",
    "                if read == 'R1':  # Reverse complement Read 2\n",
    "                    sequences[read].append(temp_seq)\n",
    "                else:  # Don't reverse complement Read 1\n",
    "                    sequences[read].append(str(Seq(temp_seq).reverse_complement()))\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def seq_find(seq, left, right, target_len, num_seqs, hamming_dist):\n",
    "    \"\"\"Identifies a target sequence using regular expressions. Sequence must be of specified length, and gaps\n",
    "    cannot exist in the flanking sequences.\n",
    "    Arguments:\n",
    "    seq: Full sequence\n",
    "    left: Left flanking sequence\n",
    "    right: Right flanking sequence\n",
    "    target_len: Length of desired sequence\n",
    "    num_seqs: Total number of desired sequences in full sequence\n",
    "    hamming_dist: Acceptable number of mismatches in flanking regions (no gaps)\n",
    "    Returns:\n",
    "    target_seq: If found, returns the desired sequence. If multiple sequences are desired, returns them all\n",
    "    \"\"\"\n",
    "    regex_string = '(' + left + '.'*target_len + right + ')' + '{s<' + str(hamming_dist) + '}'\n",
    "    target_area = regex.findall(regex_string, seq)\n",
    "    target_seq = [found[len(left):-len(right)] for found in target_area]\n",
    "    # Split the logic below to return the correct number of items\n",
    "    if num_seqs == 1:\n",
    "        if len(target_seq) == 1:\n",
    "            return target_seq[0]\n",
    "        else:\n",
    "            return 'Not found'\n",
    "    if num_seqs == 2:\n",
    "        if len(target_seq) == 2:\n",
    "            return target_seq[0], target_seq[1]\n",
    "        else:\n",
    "            return 'Not found', 'Not found'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def assign_ID(seq_dict, ID_to_seq, hamming_dist, targets):\n",
    "    \"\"\"Assigns an sgRNA ID to provided sequences. sgRNAs will be called if they match exactly one desired sequence\n",
    "    at within the provided hamming distance. Prints out summary statistics.\n",
    "    Arguments:\n",
    "    seq_dict: Dictionary containing sequences to be called\n",
    "    ID_to_seq: Dictionary relating sgRNAs to their exact sequence\n",
    "    hamming_dist: Acceptable number of mismatches\n",
    "    targets: Desired sgRNAs in the given position\n",
    "    Returns:\n",
    "    sgRNA_IDs: Dictionary containing called sgRNA IDs\n",
    "    \"\"\"\n",
    "    sg_total, sgRNA_IDs = {}, {}\n",
    "    for lib in seq_dict:\n",
    "        sgRNA_IDs[lib] = []\n",
    "        for seq in seq_dict[lib]:\n",
    "            if seq == 'Not found':\n",
    "                sgRNA_IDs[lib].append('Not found')\n",
    "                continue\n",
    "            found = []\n",
    "            for ID, ref_seq in ID_to_seq.items():\n",
    "                if sum([x1 != y1 for x1, y1 in zip(seq, ref_seq)]) <= hamming_dist:  # Finds hamming distance\n",
    "                    found += [ID]\n",
    "            if len(found) == 1:  # Uniquely mapped sequences\n",
    "                sgRNA_IDs[lib].append(found[0])\n",
    "                if found[0] in sg_total:\n",
    "                    sg_total[found[0]] += 1\n",
    "                else:\n",
    "                    sg_total[found[0]] = 1\n",
    "            elif found:  # Not uniquely mapped\n",
    "                sgRNA_IDs[lib].append('Multiple')\n",
    "            else:  # None mapped\n",
    "                sgRNA_IDs[lib].append('None')\n",
    "    print(f'Percent assigned: \\\n",
    "            {np.round(100*sum(list(sg_total.values()))/(sum(len(seq_dict[lib]) for lib in seq_dict)), 3)}%')\n",
    "    total_targets = 0\n",
    "    for sgRNA in sg_total:\n",
    "        if sgRNA in targets:\n",
    "            total_targets += sg_total[sgRNA]\n",
    "    print(f'Percent wanted: {np.round(100*total_targets/sum(sg_total.values()), 3)}%')\n",
    "    return sgRNA_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qtest_dixon(replicates):\n",
    "    \"\"\"One-sided Dixon Q test at 95% confidence: Statistical test used for identyfing outliers in data set\n",
    "    https://www.philadelphia.edu.jo/academics/ajaber/uploads/0501522-Chapter%203-Statiscal%20tests.pdf\n",
    "    Used here to identify CRISPRi escapers: replicates with abnormally fast growth rates\n",
    "    Argument:\n",
    "    replicates: List of growth rate replicates to test for an outlier\n",
    "    Returns:\n",
    "    rep_sorted[:-1] or replicates: If an escaper was found, removes it. Otherwise, returns all replicates\n",
    "    rep_sorted[-1] or np.nan: If an escaper was found, returns the escaper. Otherwise, returns nan.\n",
    "    \"\"\"\n",
    "    Q30 = [0, 0, 0.941, 0.765, 0.642, 0.560]  # One-sided values, 95% confidence\n",
    "    if len(replicates) >= 4:\n",
    "        rep_sorted = sorted(replicates)\n",
    "        gap = abs(rep_sorted[-2] - rep_sorted[-1])\n",
    "        rep_range = rep_sorted[-1] - rep_sorted[0]\n",
    "        if rep_range != 0:  # If all values are equal, can't run this test\n",
    "            Q_val = gap / rep_range\n",
    "            if Q_val >= Q30[len(replicates)-1]:\n",
    "                return rep_sorted[:-1], rep_sorted[-1]\n",
    "    return replicates, np.nan\n",
    "\n",
    "\n",
    "def third_order_gr(avals_list, repression_list, params):\n",
    "    \"\"\"Calculates an expected growth rate following three separate CRISPRi perturbations. Accounts for coupling\n",
    "    between repression\n",
    "    Arguments:\n",
    "    avals_list: List of coupling constants, ordered ij, ik, ji, jk, ki, kj (1-2, 1-3, 2-1, 2-3, 3-1, 3-2)\n",
    "    repression_list: List of repression intensities to predict for all three knockdowns.\n",
    "    params: Single-knockdown sigmoidal parameters.\n",
    "    Returns:\n",
    "    full_gr_list: A list of four lists. The first three are the relative growth rate contributions of each\n",
    "                  repression individually (after accounting for coupling), and the fourth is the overall growth rate.\n",
    "    \"\"\"\n",
    "    Ro_list = [x[0] for x in params]  # Extract all R0 values\n",
    "    reff_list, resids_list = solveReff_third(avals_list, repression_list, Ro_list)\n",
    "    r1eff, r2eff, r3eff = reff_list  # Extract individual effective repressions\n",
    "    gr1, gr2, gr3 = np.zeros(np.shape(r1eff)), np.zeros(np.shape(r2eff)), np.zeros(np.shape(r3eff))\n",
    "    gr_triple = np.zeros(np.shape(r1eff))\n",
    "    for i in range(len(repression_list[0])):\n",
    "        for j in range(len(repression_list[1])):\n",
    "            for k in range(len(repression_list[2])):\n",
    "                gr1[i, j, k] = growth_rate(r1eff[i, j, k], params[0][0], params[0][1])\n",
    "                gr2[i, j, k] = growth_rate(r2eff[i, j, k], params[1][0], params[1][1])\n",
    "                gr3[i, j, k] = growth_rate(r3eff[i, j, k], params[2][0], params[2][1])\n",
    "                gr_triple[i, j, k] = gr1[i, j, k] * gr2[i, j, k] * gr3[i, j, k]\n",
    "    full_gr_list = [gr1, gr2, gr3, gr_triple]\n",
    "    return full_gr_list\n",
    "\n",
    "\n",
    "def solveReff_third(avals_list, repression_list, Ro_list):\n",
    "    \"\"\"Solve for the effective repression of three CRISPRi perturbations, given six coupling constants\n",
    "    describing all pairwise couplings between them.\n",
    "    Arguments:\n",
    "    avals_list: List of coupling constants, ordered ij, ik, ji, jk, ki, kj (1-2, 1-3, 2-1, 2-3, 3-1, 3-2)\n",
    "    repression_list: List of repression intensities to predict for all three knockdowns.\n",
    "    params: Single-knockdown sigmoidal parameters.\n",
    "    Ro_list: List of three Ro (repression at half-maximal growth rate) parameters\n",
    "    Returns:\n",
    "    reff_list: Three lists of each perturbation's relative repression after accounting for coupling\n",
    "    resids_list: List of residuals, returned for troubleshooting and optimization\n",
    "    \"\"\"\n",
    "    rep_1, rep_2, rep_3 = repression_list\n",
    "    Ro_1, Ro_2, Ro_3 = Ro_list\n",
    "    r1eff = np.zeros((len(rep_1), len(rep_2), len(rep_3)))\n",
    "    r2eff = np.zeros((len(rep_1), len(rep_2), len(rep_3)))\n",
    "    r3eff = np.zeros((len(rep_1), len(rep_2), len(rep_3)))\n",
    "    for i in range(len(rep_1)):\n",
    "        for j in range(len(rep_2)):\n",
    "            for k in range(len(rep_3)):\n",
    "                r1eff[:, j, k] = rep_1\n",
    "                r2eff[i, :, k] = rep_2\n",
    "                r3eff[i, j, :] = rep_3\n",
    "    r1update = np.zeros(np.shape(r1eff))\n",
    "    r2update = np.zeros(np.shape(r2eff))\n",
    "    r3update = np.zeros(np.shape(r3eff))\n",
    "    resids, eps, count = np.inf, 0.01, 0  # Initialize sum of residuals, desired final residual, and count iterator\n",
    "    resids_r1, resids_r2, resids_r3 = [], [], []\n",
    "    # Iteratively reduce the residuals using the update formulas\n",
    "    # If the desired residual is not reached, exit after 100 iterations\n",
    "    while resids > eps and count < 100:\n",
    "        for i, r1 in enumerate(rep_1):\n",
    "            for j, r2 in enumerate(rep_2):\n",
    "                for k, r3 in enumerate(rep_3):\n",
    "                    r1update[i, j, k] = r1 \\\n",
    "                    / ((1 + avals_list[0]*((r2eff[i, j, k]/Ro_2)/(1 + (r2eff[i, j, k]/Ro_2))))\n",
    "                    * (1 + avals_list[2]*((r3eff[i, j, k]/Ro_3)/(1 + (r3eff[i, j, k]/Ro_3)))))\n",
    "                    r2update[i, j, k] = r2 \\\n",
    "                    / ((1 + avals_list[1]*((r1eff[i, j, k]/Ro_1)/(1 + (r1eff[i, j, k]/Ro_1))))\n",
    "                    * (1 + avals_list[4]*((r3eff[i, j, k]/Ro_3)/(1 + (r3eff[i, j, k]/Ro_3)))))\n",
    "                    r3update[i, j, k] = r3 \\\n",
    "                    / ((1 + avals_list[3]*((r1eff[i, j, k]/Ro_1)/(1 + (r1eff[i, j, k]/Ro_1))))\n",
    "                    * (1 + avals_list[5]*((r2eff[i, j, k]/Ro_2)/(1 + (r2eff[i, j, k]/Ro_2)))))\n",
    "        resids_r1.append(np.sum(abs(r1eff - r1update)))\n",
    "        resids_r2.append(np.sum(abs(r2eff - r2update)))\n",
    "        resids_r3.append(np.sum(abs(r3eff - r3update)))\n",
    "        resids = resids_r1[-1] + resids_r2[-1] + resids_r3[-1]\n",
    "        r1eff = np.copy(r1update)\n",
    "        r2eff = np.copy(r2update)\n",
    "        r3eff = np.copy(r3update)\n",
    "        count += 1\n",
    "    reff_list = [r1eff, r2eff, r3eff]\n",
    "    resids_list = [resids_r1, resids_r2, resids_r3]\n",
    "    return reff_list, resids_list\n",
    "\n",
    "\n",
    "def growth_rate(r, Ro, n):\n",
    "    \"\"\"Calculates an expected growth rate using a sigmoidal formula.\n",
    "    Arguments:\n",
    "    r: Repression level to use when predicting growth rates\n",
    "    Ro: Repression level at half-maximal growth rate\n",
    "    n: Steepness of the repression-growth rate function\n",
    "    Returns:\n",
    "    g_rate: Predicted growth rate\n",
    "    \"\"\"\n",
    "    g_rate = 1 / (1+math.exp(n*(r-Ro)))\n",
    "    return g_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanrms(x, axis=None):\n",
    "    \"\"\"Self-defined root mean square function. Used for convenience and consistency.\n",
    "    Arguments:\n",
    "    x: Array of residuals\n",
    "    axis: In case of an array of arrays, enter the desired axis to calculate across\n",
    "    Directly returns the RMSD of the residuals provided\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean(x**2, axis=axis))\n",
    "\n",
    "\n",
    "def model_plot(exp_gr_mean, model_pred, null_pred, num_nont, figure_path, fig_names=None):\n",
    "    \"\"\"Function for plotting correlations between predicted and experimental growth rate data.\n",
    "    Creates two plots: the first using the coupling-sensitive model, the second using the Null model.\n",
    "    Inputs can separate graphs based on how many nontargeting sgRNAs are present in each construct.\n",
    "    Arguments:\n",
    "    exp_gr_mean: Experimentally determined growth rates (Real)\n",
    "    model_pred: Predicted growth rates from the coupling-sensitive model (Model)\n",
    "    null_pred: Predicted growth rates from the Null model (Null)\n",
    "    num_nont: A list containing acceptable numbers of nontargeting sgRNAs to plot.\n",
    "    For example, [0] would only plot constructs with three targeting sgRNAs.\n",
    "    [1, 2, 3] plots all other constructs, including the control construct. \n",
    "    [0, 1, 2, 3] plots all data\n",
    "    figure_path: Path to a folder storing figure output\n",
    "    fig_names: List of names for the saved figures, if desired\n",
    "    \"\"\"\n",
    "    # Organize data\n",
    "    colors, data_dict = [], {'Exp':[], 'Epistatic':[], 'Null':[]}\n",
    "    for full_sgRNA in exp_gr_mean:\n",
    "        if ~np.isnan(exp_gr_mean[full_sgRNA]):\n",
    "            # Check if this construct should be plotted\n",
    "            if sum([sgRNA == 'negC_rand_42' for sgRNA in full_sgRNA.split('-')]) in num_nont:\n",
    "                data_dict['Exp'].append(exp_gr_mean[full_sgRNA])\n",
    "                data_dict['Epistatic'].append(model_pred[full_sgRNA])\n",
    "                data_dict['Null'].append(null_pred[full_sgRNA])\n",
    "    # Generate plots\n",
    "    for i, model in enumerate(['Epistatic', 'Null']):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.scatter(data_dict['Exp'], data_dict[model], color='xkcd:gray', s=60, ec='xkcd:dark gray', zorder=2)\n",
    "        ax.plot([0, 1.2], [0, 1.2], lw=1, color='xkcd:dark gray', ls='--', zorder=0)\n",
    "        ax.set_xlim([0, 1.2])\n",
    "        ax.set_ylim([0, 1.2])\n",
    "        ax.set_xticks([0.5, 1])\n",
    "        ax.set_yticks([0.5, 1])\n",
    "        ax.set_xlabel('Tri sgRNA Data', fontsize=20)\n",
    "        ax.set_ylabel(f'{model} Prediction', fontsize=20)\n",
    "        ax.text(0.02, 1, f\"RMSD: {np.round(nanrms(np.array(data_dict['Exp']) - np.array(data_dict[model])), 3)}\",\n",
    "                fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        if fig_names:\n",
    "            plt.savefig(f'{figure_path}/Fig{fig_names[i]}.pdf')\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign sgRNA construct IDs from FASTQ files\n",
    "\n",
    "This code cannot run without first downloading the sequencing files for the third-order library (see publication for details). Once downloaded, define the seq_path variable to connect to the sequencing files, then run the following code. Its output is saved so this analysis can continue without downloading sequencing files.\n",
    "\n",
    "The following code first extracts sequencing reads from Illumina paired-end FASTQ files, reverse-complenting the necessary read to standardize both sequences. Then, using regular expressions, it locates three 20 bp sgRNA homology sequences and one 6 bp BC sequence from each read. These sequences are assigned IDs based on a sequence-sgRNA lookup dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "seq_path = ''\n",
    "# Extract full sequences from FASTQ files\n",
    "sequences = {}\n",
    "for read_file in read_file_list:\n",
    "    sp = read_file.split('_')\n",
    "    sequences[sp[0]] = read_seqs(read_file, seq_path)\n",
    "# Identify three sgRNA sequences and the barcode sequnence from the fastq files\n",
    "sgRNA1_dict, sgRNA2_dict, sgRNA3_dict, BC_dict = {}, {}, {}, {}\n",
    "for read_file in read_file_list:\n",
    "    sp = read_file.split('_')\n",
    "    sgRNA1_dict[sp[0]] = []\n",
    "    sgRNA2_dict[sp[0]] = []\n",
    "    sgRNA3_dict[sp[0]] = []\n",
    "    BC_dict[sp[0]] = []\n",
    "    for ind in range(len(sequences[sp[0]]['R1'])):\n",
    "        sgRNA2_seq, sgRNA1_seq = seq_find(sequences[sp[0]]['R2'][ind], 'CTAGCTCTAAAAC', 'ACTAGTATTATAC', 20, 2, 10)\n",
    "        sgRNA3_seq = seq_find(sequences[sp[0]]['R1'][ind], 'CTAGCTCTAAAAC', 'ACTAGTATTATAC', 20, 1, 6)\n",
    "        BC_seq = seq_find(sequences[sp[0]]['R1'][ind], 'GTACAGCGAGGCAAC', 'ACGGATCCCCAC', 6, 1, 6)\n",
    "        sgRNA1_dict[sp[0]].append(sgRNA1_seq)\n",
    "        sgRNA2_dict[sp[0]].append(sgRNA2_seq)\n",
    "        sgRNA3_dict[sp[0]].append(sgRNA3_seq)\n",
    "        BC_dict[sp[0]].append(BC_seq)\n",
    "# Assign sgRNA names from sequences\n",
    "sgRNA1_IDs = assign_ID(sgRNA1_dict, sgRNA2seq, 2, sg1targets)\n",
    "sgRNA2_IDs = assign_ID(sgRNA2_dict, sgRNA2seq, 8, sg2targets)\n",
    "sgRNA3_IDs = assign_ID(sgRNA3_dict, sgRNA2seq, 0, sg3targets)\n",
    "# Combine individual sgRNA and BC calls to complete constructs\n",
    "# Only counts sequencing reads that have three correctly called sgRNAs and a barcode across all timepoints. \n",
    "total_sgRNA_BC = {}\n",
    "for tp in sgRNA1_IDs:\n",
    "    total_sgRNA_BC[tp] = {}\n",
    "    for BC in BC_list:\n",
    "        total_sgRNA_BC[tp][BC] = {}\n",
    "    for i, sgRNA1 in enumerate(sgRNA1_IDs[tp]):\n",
    "        sgRNA2 = sgRNA2_IDs[tp][i]\n",
    "        sgRNA3 = sgRNA3_IDs[tp][i]\n",
    "        BC = BC_dict[tp][i]\n",
    "        if sgRNA1 in sgRNA2seq and sgRNA2 in sgRNA2seq and sgRNA3 in sgRNA2seq and BC in BC_list:\n",
    "            if sgRNA1 in sg1targets and sgRNA2 in sg2targets and sgRNA3 in sg3targets:\n",
    "                full = f'{sgRNA1}-{sgRNA2}-{sgRNA3}'\n",
    "                if full in total_sgRNA_BC[tp][BC]:\n",
    "                    total_sgRNA_BC[tp][BC][full] += 1\n",
    "                else:\n",
    "                    total_sgRNA_BC[tp][BC][full] = 1\n",
    "# Save outupt\n",
    "with open(f'{input_path}/third_order_counts.pickle', 'wb') as handle:\n",
    "    pickle.dump(total_sgRNA_BC, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the overall distribution of sgRNA constructs across all barcodes and timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "xVals = []\n",
    "for tp in total_sgRNA_BC:\n",
    "    for BC in BC_list:\n",
    "        xVals += list(total_sgRNA_BC[tp][BC].values())\n",
    "ax.hist(xVals, bins=[10**(x/4) for x in range(14)])\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('# Counts', fontsize=20)\n",
    "ax.set_ylabel('# Constructs', fontsize=20)\n",
    "plt.show()\n",
    "# Check how many unique barcoded constructs were present at T0\n",
    "num_xVals_T0 = [len(total_sgRNA_BC['T0'][BC].values()) for BC in BC_list]\n",
    "print(f'Percent of sequences identified at T0: {np.round(sum(num_xVals_T0)/(5*5*9*6)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate relative sgRNA frequency and growth rates\n",
    "\n",
    "We first normalize raw counts by the nontargeting construct at each timepoint. Then we normalize relative frequencies at every timepoint by the relative frequency at $T_0$. For all constructs with counts present through the first three timepoints, we fit a line to $log_2$(relative frequency) vs. time data. The slope of this line is the construct's relative growth rate effect.\n",
    "\n",
    "$relative frequency_{a,T}$ = $\\frac{counts_{a,T} / counts_{Nont,T}}{counts_{a,T_0} / counts_{Nont,T_0}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nont = 'negC_rand_42-negC_rand_42-negC_rand_42'\n",
    "gr_dict, b_dict = {}, {}\n",
    "for BC in BC_list:\n",
    "    gr_dict[BC], b_dict[BC] = {}, {}\n",
    "    for sg1 in sg1targets:\n",
    "        for sg2 in sg2targets:\n",
    "            for sg3 in sg3targets:\n",
    "                full_sgRNA = f'{sg1}-{sg2}-{sg3}'\n",
    "                temp_vals, temp_tp = [], []\n",
    "                for tp in total_sgRNA_BC:\n",
    "                    if full_sgRNA in total_sgRNA_BC[tp][BC]:\n",
    "                        temp_vals.append(total_sgRNA_BC[tp][BC][full_sgRNA]/total_sgRNA_BC[tp][BC][nont])\n",
    "                        temp_tp.append(int(tp[1:])*turb_gr['tri'])\n",
    "                        if total_sgRNA_BC[tp][BC][full_sgRNA] < 1:\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "                if len(temp_tp) >= 3:\n",
    "                    norm_vals = [np.log2(x/temp_vals[0]) for x in temp_vals]\n",
    "                    gr_dict[BC][full_sgRNA], b_dict[BC][full_sgRNA], r_value, p_value, std_err = \\\n",
    "                    stats.linregress(temp_tp, norm_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escaper correction and rescaling\n",
    "\n",
    "We first remove escapers, as before, using a one-sided Dixon Q-test at 95% confidence. After removing escapers, we average all constructs with at least four barcoded measurements remaining. Then, we normalize each construct's mean growth rate by the minimum growth rate observed in the pairwise CRISPRi library, which rescales the nontargeting construct's growth rate to 1 and makes all growth rates non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escaper_dict_tri, gr_mean_dict, gr_std_dict, gr_sem_dict, gr_mean_rescale_dict, gr_std_rescale_dict, \\\n",
    "gr_sem_rescale_dict = {}, {}, {}, {}, {}, {}, {}\n",
    "for sg1 in sg1targets:\n",
    "    for sg2 in sg2targets:\n",
    "        for sg3 in sg3targets:\n",
    "            full_sgRNA = f'{sg1}-{sg2}-{sg3}'\n",
    "            temp_vals = []\n",
    "            for BC in BC_list:\n",
    "                if full_sgRNA in gr_dict[BC]:\n",
    "                    temp_vals.append(gr_dict[BC][full_sgRNA])\n",
    "            if len(temp_vals) >= 4:\n",
    "                v_values, escaper_val = qtest_dixon(temp_vals)\n",
    "                if not np.isnan(escaper_val):\n",
    "                    escaper_dict_tri[full_sgRNA] = escaper_val\n",
    "                gr_mean_dict[full_sgRNA] = np.mean(v_values)\n",
    "                gr_std_dict[full_sgRNA] = np.std(v_values)\n",
    "                gr_sem_dict[full_sgRNA] = stats.sem(v_values)\n",
    "                gr_mean_rescale_dict[full_sgRNA] = (np.mean(v_values)+abs(min_gr)) / abs(min_gr)\n",
    "                gr_std_rescale_dict[full_sgRNA] = np.std(v_values) / abs(min_gr)\n",
    "                gr_sem_rescale_dict[full_sgRNA] = stats.sem(v_values) / abs(min_gr)\n",
    "            else:\n",
    "                gr_mean_dict[full_sgRNA] = np.nan\n",
    "                gr_std_dict[full_sgRNA] = np.nan\n",
    "                gr_sem_dict[full_sgRNA] = np.nan\n",
    "                gr_mean_rescale_dict[full_sgRNA] = np.nan\n",
    "                gr_std_rescale_dict[full_sgRNA] = np.nan\n",
    "                gr_sem_rescale_dict[full_sgRNA] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot single- and pairwise knockdown growth rates relative to the pairwise only library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# The coloring scheme and 2D error bars necessitate a bit of data reshuffling\n",
    "xVals_s, yVals_s, x_sem_s, y_sem_s, xVals_p, yVals_p, x_sem_p, y_sem_p = [], [], [], [], [], [], [], []\n",
    "for full_sgRNA in gr_mean_dict:\n",
    "    if ~np.isnan(gr_mean_dict[full_sgRNA]):\n",
    "        sp = full_sgRNA.split('-')\n",
    "        guides = [x for x in sp if x != 'negC_rand_42']\n",
    "        if len(guides) == 1:\n",
    "            xVals_s.append(gr_mean_rescale_dict[full_sgRNA])\n",
    "            yVals_s.append(pairwise_gr_rescale.loc[guides[0], 'negC_rand_42'])\n",
    "            x_sem_s.append(gr_sem_rescale_dict[full_sgRNA])\n",
    "            y_sem_s.append(pairwise_sem_rescale.loc[guides[0], 'negC_rand_42'])\n",
    "        elif len(guides) == 2:\n",
    "            if ~np.isnan(pairwise_gr_rescale.loc[guides[0], guides[1]]):\n",
    "                xVals_p.append(gr_mean_rescale_dict[full_sgRNA])\n",
    "                yVals_p.append(pairwise_gr_rescale.loc[guides[0], guides[1]])\n",
    "                x_sem_p.append(gr_sem_rescale_dict[full_sgRNA])\n",
    "                y_sem_p.append(pairwise_sem_rescale.loc[guides[0], guides[1]])\n",
    "            elif ~np.isnan(pairwise_gr_rescale.loc[guides[1], guides[0]]):\n",
    "                xVals_p.append(gr_mean_rescale_dict[full_sgRNA])\n",
    "                yVals_p.append(pairwise_gr_rescale.loc[guides[1], guides[0]])\n",
    "                x_sem_p.append(gr_sem_rescale_dict[full_sgRNA])\n",
    "                y_sem_p.append(pairwise_sem_rescale.loc[guides[1], guides[0]])\n",
    "ax.errorbar(xVals_s, yVals_s, xerr=x_sem_s, yerr=y_sem_s, fmt='o', mec='xkcd:dark gray', ms=10, c='xkcd:orange')\n",
    "ax.errorbar(xVals_p, yVals_p, xerr=x_sem_p, yerr=y_sem_p, fmt='o', mec='xkcd:dark gray', ms=10, c='b', zorder=0)\n",
    "ax.set_xlim([0, 1.2])\n",
    "ax.set_ylim([0, 1.2])\n",
    "ax.set_xticks([0.5, 1])\n",
    "ax.set_yticks([0.5, 1])\n",
    "ax.set_xlabel('Tri sgRNA GR', fontsize=20)\n",
    "ax.set_ylabel('Pairwise sgRNA GR', fontsize=20)\n",
    "xVals_full = np.concatenate((np.array(xVals_s), np.array(xVals_p)))\n",
    "yVals_full = np.concatenate((np.array(yVals_s), np.array(yVals_p)))\n",
    "ax.text(0.06, 0.9, f'RMSD: {np.round(nanrms(xVals_full - yVals_full), 3)}', fontsize=14)\n",
    "ax.plot([-0.1, 1.3], [-0.1, 1.3], lw=1, color='xkcd:dark gray', ls='--')\n",
    "ax.text(0.8, 0.06, 'Single sgRNA', c='xkcd:orange', fontsize=14)\n",
    "ax.text(0.8, 0.16, 'Double sgRNA', c='b', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{figure_path}/FigS8.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting third-order growth rates\n",
    "\n",
    "To predict growth rates of these third-order CRISPRi constructs, we need each sgRNA's repression intensity, which we extract from qPCR data. Then, we use these repression values, each gene's repression-growth rate function, and the relevant coupling constants to calculate effective repression values for each perturbation. Finally, we combine these to calculate a predicted growth rate following each perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgRNA_dict, qPCR_dict = {}, {}\n",
    "sgRNA_dict['dapA'] = ['negC_rand_42', 'dapA_3_214_B_MM9', 'dapA_3_214_C']\n",
    "sgRNA_dict['dapB'] = ['negC_rand_42', 'dapB_1_18_B_MM11', 'dapB_1_18_C']\n",
    "sgRNA_dict['purN'] = ['negC_rand_42', 'purN_3_238_B_MM11', 'purN_1_86_C']\n",
    "sgRNA_dict['purL'] = ['negC_rand_42', 'purL_3_201_B_MM5', 'purL_3_201_C']\n",
    "sgRNA_dict['folA'] = ['negC_rand_42', 'folA_1_56_B_MM10', 'folA_1_56_B_MM3']\n",
    "sgRNA_dict['thyA'] = ['negC_rand_42', 'thyA_3_233_B_MM5', 'thyA_3_233_C']\n",
    "sgRNA_dict['gltB'] = ['negC_rand_42', 'gltB_3_284_B_MM10', 'gltB_3_284_C']\n",
    "sgRNA_dict['gdhA'] = ['negC_rand_42', 'gdhA_1_42_B_MM8', 'gdhA_1_42_C']\n",
    "for gene, sgRNA_list in sgRNA_dict.items():\n",
    "    qPCR_dict[gene] = [qPCR_vals[gene][sgRNA] for sgRNA in sgRNA_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_trip_dict, gr_null_dict = {}, {}\n",
    "for gene1 in ['gdhA', 'dapA']:\n",
    "    for gene2 in ['gltB', 'dapB']:\n",
    "        for gene3 in ['folA', 'thyA', 'purN', 'purL']:\n",
    "            gene_set, avals_list = [gene1, gene2, gene3], []\n",
    "            for subset in itertools.combinations(gene_set, 2):  # All pairwise combinations\n",
    "                if (subset[0], subset[1]) in pair_avals:  # This logic corrects for gene order\n",
    "                    avals_list += list(pair_avals[(subset[0], subset[1])])\n",
    "                else:\n",
    "                    avals_list += list(pair_avals[(subset[1], subset[0])])\n",
    "            repression_list, params = [], []\n",
    "            for gene in gene_set:\n",
    "                repression_list.append(qPCR_dict[gene])\n",
    "                params.append(list(hill_elements[gene]))\n",
    "            gr_list = third_order_gr(avals_list, repression_list, params)\n",
    "            gr_list_null = third_order_gr(np.array([0, 0, 0, 0, 0, 0]), repression_list, params)\n",
    "            for i, sg1 in enumerate(sgRNA_dict[gene1]):\n",
    "                for j, sg2 in enumerate(sgRNA_dict[gene2]):\n",
    "                    for k, sg3 in enumerate(sgRNA_dict[gene3]):\n",
    "                        full_sgRNA = f'{sg1}-{sg2}-{sg3}'\n",
    "                        gr_trip_dict[full_sgRNA] = gr_list[-1][i, j, k]\n",
    "                        gr_null_dict[full_sgRNA] = gr_list_null[-1][i, j, k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results of the coupling-sensitive model predictions and Null model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plot(gr_mean_rescale_dict, gr_trip_dict, gr_null_dict, [1, 2], figure_path, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plot(gr_mean_rescale_dict, gr_trip_dict, gr_null_dict, [0], figure_path, ['5C', '5D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plot(gr_mean_rescale_dict, gr_trip_dict, gr_null_dict, [0, 1, 2, 3], figure_path, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tables and export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_s5 = pd.DataFrame(np.full((len(gr_mean_rescale_dict), 7), np.nan), columns=['sgRNA1', 'sgRNA2', 'sgRNA3',\n",
    "                                            'Growth Rate', 'Growth Rate SEM', 'Model Prediction', 'Null Prediction'])\n",
    "for i, full_sgRNA in enumerate(gr_mean_rescale_dict):\n",
    "    sgRNA_split = full_sgRNA.split('-')\n",
    "    table_s5.loc[i] = [sgRNA_split[0], sgRNA_split[1], sgRNA_split[2], gr_mean_rescale_dict[full_sgRNA],\n",
    "                      gr_sem_rescale_dict[full_sgRNA], gr_trip_dict[full_sgRNA], gr_null_dict[full_sgRNA]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'Supplementary_Tables.xlsx', mode='a', if_sheet_exists='replace') as writer:  \n",
    "    table_s5.to_excel(writer, sheet_name='Table S5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
